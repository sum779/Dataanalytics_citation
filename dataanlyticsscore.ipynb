{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e6e57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Country</th>\n",
       "      <th>Author</th>\n",
       "      <th>URLS</th>\n",
       "      <th>ArticleType</th>\n",
       "      <th>...</th>\n",
       "      <th>RetractionDOI</th>\n",
       "      <th>RetractionPubMedID</th>\n",
       "      <th>OriginalPaperDate</th>\n",
       "      <th>OriginalPaperDOI</th>\n",
       "      <th>OriginalPaperPubMedID</th>\n",
       "      <th>RetractionNature</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Paywalled</th>\n",
       "      <th>Notes</th>\n",
       "      <th>CitationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50792</td>\n",
       "      <td>A fractional order nonlinear model of the love...</td>\n",
       "      <td>(B/T) Data Science;(PHY) Mathematics;</td>\n",
       "      <td>Department of Mathematical Sciences, College o...</td>\n",
       "      <td>Scientific Reports</td>\n",
       "      <td>Springer - Nature Publishing Group</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Zulqurnain Sabir;Salem Ben Said</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Article;</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1038/s41598-024-51277-3</td>\n",
       "      <td>38191570.0</td>\n",
       "      <td>3/04/2023</td>\n",
       "      <td>10.1038/s41598-023-32497-5</td>\n",
       "      <td>37012356.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>+Duplication of Article;+Euphemisms for Duplic...</td>\n",
       "      <td>No</td>\n",
       "      <td>See also: https://pubpeer.com/publications/E4F...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50782</td>\n",
       "      <td>Investigation of automotive digital mirrors er...</td>\n",
       "      <td>(PHY) Engineering - Mechanical;</td>\n",
       "      <td>Department of Physics, Faculty of Science, Cai...</td>\n",
       "      <td>Journal of Optics (India)</td>\n",
       "      <td>Springer</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>H S Ayoub;Wessam M Hussein;Y H Elbashar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Article;</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1007/s12596-023-01630-y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/01/2021</td>\n",
       "      <td>10.1007/s12596-021-00677-z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>+Fake Peer Review;+Investigation by Journal/Pu...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50781</td>\n",
       "      <td>Optical spectroscopic analysis of bandpass fil...</td>\n",
       "      <td>(PHY) Chemistry;(PHY) Crystallography/Spectros...</td>\n",
       "      <td>Egypt Nanotechnology Center ((EGNC)), Cairo Un...</td>\n",
       "      <td>Journal of Optics (India)</td>\n",
       "      <td>Springer</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Y H Elbashar;M A Mohamed;D Rayan;A M Badr;H A ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Article;</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1007/s12596-023-01628-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5/05/2020</td>\n",
       "      <td>10.1007/s12596-020-00611-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retraction</td>\n",
       "      <td>+Concerns/Issues with Peer Review;+Fake Peer R...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record ID                                              Title  \\\n",
       "0      50792  A fractional order nonlinear model of the love...   \n",
       "1      50782  Investigation of automotive digital mirrors er...   \n",
       "2      50781  Optical spectroscopic analysis of bandpass fil...   \n",
       "\n",
       "                                             Subject  \\\n",
       "0              (B/T) Data Science;(PHY) Mathematics;   \n",
       "1                    (PHY) Engineering - Mechanical;   \n",
       "2  (PHY) Chemistry;(PHY) Crystallography/Spectros...   \n",
       "\n",
       "                                         Institution  \\\n",
       "0  Department of Mathematical Sciences, College o...   \n",
       "1  Department of Physics, Faculty of Science, Cai...   \n",
       "2  Egypt Nanotechnology Center ((EGNC)), Cairo Un...   \n",
       "\n",
       "                     Journal                           Publisher  \\\n",
       "0         Scientific Reports  Springer - Nature Publishing Group   \n",
       "1  Journal of Optics (India)                            Springer   \n",
       "2  Journal of Optics (India)                            Springer   \n",
       "\n",
       "                Country                                             Author  \\\n",
       "0  United Arab Emirates                    Zulqurnain Sabir;Salem Ben Said   \n",
       "1                 Egypt            H S Ayoub;Wessam M Hussein;Y H Elbashar   \n",
       "2                 Egypt  Y H Elbashar;M A Mohamed;D Rayan;A M Badr;H A ...   \n",
       "\n",
       "  URLS        ArticleType  ...               RetractionDOI RetractionPubMedID  \\\n",
       "0  NaN  Research Article;  ...  10.1038/s41598-024-51277-3         38191570.0   \n",
       "1  NaN  Research Article;  ...  10.1007/s12596-023-01630-y                0.0   \n",
       "2  NaN  Research Article;  ...  10.1007/s12596-023-01628-6                0.0   \n",
       "\n",
       "   OriginalPaperDate            OriginalPaperDOI OriginalPaperPubMedID  \\\n",
       "0          3/04/2023  10.1038/s41598-023-32497-5            37012356.0   \n",
       "1         12/01/2021  10.1007/s12596-021-00677-z                   0.0   \n",
       "2          5/05/2020  10.1007/s12596-020-00611-9                   0.0   \n",
       "\n",
       "   RetractionNature                                             Reason  \\\n",
       "0        Retraction  +Duplication of Article;+Euphemisms for Duplic...   \n",
       "1        Retraction  +Fake Peer Review;+Investigation by Journal/Pu...   \n",
       "2        Retraction  +Concerns/Issues with Peer Review;+Fake Peer R...   \n",
       "\n",
       "  Paywalled                                              Notes CitationCount  \n",
       "0        No  See also: https://pubpeer.com/publications/E4F...             5  \n",
       "1        No                                                NaN             2  \n",
       "2        No                                                NaN            14  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming retractions35215.csv is in the current directory\n",
    "df = pd.read_csv(\"retractions35215.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3990d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ...........................svr__C=0.1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=0.1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=0.1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=0.1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=0.1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .........................svr__C=0.1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=0.1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=0.1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=0.1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=0.1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ........................svr__C=0.1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=0.1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=0.1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=0.1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=0.1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .......................svr__C=0.1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=0.1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=0.1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=0.1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=0.1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .............................svr__C=1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .............................svr__C=1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .............................svr__C=1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .............................svr__C=1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .............................svr__C=1, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=1, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ..........................svr__C=1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ..........................svr__C=1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ..........................svr__C=1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ..........................svr__C=1, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .........................svr__C=1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .........................svr__C=1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .........................svr__C=1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .........................svr__C=1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .........................svr__C=1, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ............................svr__C=10, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ............................svr__C=10, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ............................svr__C=10, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ............................svr__C=10, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ............................svr__C=10, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=10, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=10, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=10, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=10, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ..........................svr__C=10, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=10, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .........................svr__C=10, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .........................svr__C=10, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .........................svr__C=10, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .........................svr__C=10, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=10, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ........................svr__C=10, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ........................svr__C=10, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ........................svr__C=10, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ........................svr__C=10, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END ...........................svr__C=100, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=100, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=100, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=100, svr__gamma=1; total time=   0.0s\n",
      "[CV] END ...........................svr__C=100, svr__gamma=1; total time=   0.0s\n",
      "[CV] END .........................svr__C=100, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=100, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=100, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=100, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END .........................svr__C=100, svr__gamma=0.1; total time=   0.0s\n",
      "[CV] END ........................svr__C=100, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=100, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=100, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=100, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END ........................svr__C=100, svr__gamma=0.01; total time=   0.0s\n",
      "[CV] END .......................svr__C=100, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=100, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=100, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=100, svr__gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................svr__C=100, svr__gamma=0.001; total time=   0.0s\n",
      "Mean Squared Error comparison:\n",
      "SVR with standardization (linear) --> 0.002\n",
      "SVR with standardization (RBF) --> 0.002\n",
      "Tuned SVR with standardization (RBF) --> 0.002\n",
      "Random Forest --> 0.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load the dataset\n",
    "retraction = pd.read_csv(\"retractions35215.csv\")\n",
    "\n",
    "# Keep only the required columns\n",
    "retractions = retraction[['CitationCount', 'OriginalPaperDate', 'ArticleType', 'RetractionDate']]\n",
    "\n",
    "# Handling missing values (Dropping Null Rows)\n",
    "retractions = retractions.dropna()\n",
    "\n",
    "# Feature Engineering\n",
    "retractions['Publication_Year'] = pd.to_datetime(retractions['OriginalPaperDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Year'] = pd.to_datetime(retractions['RetractionDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Lag'] = (retractions['Retraction_Year'] - retractions['Publication_Year']) / 365.25\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "retractions['ArticleType'] = le.fit_transform(retractions['ArticleType'])\n",
    "\n",
    "# Select features and target variable\n",
    "X = retractions[['CitationCount', 'Publication_Year', 'ArticleType']]\n",
    "y = retractions['Retraction_Lag']\n",
    "\n",
    "# Splitting data into 50% training and 50% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Support Vector Regression with linear kernel and standardization via pipeline\n",
    "svr_linear = make_pipeline(StandardScaler(), SVR(kernel='linear'))\n",
    "svr_linear.fit(X_train, y_train)\n",
    "mse_svr_linear = mean_squared_error(y_test, svr_linear.predict(X_test))\n",
    "\n",
    "# Support Vector Regression with RBF kernel and standardization via pipeline\n",
    "svr_rbf = make_pipeline(StandardScaler(), SVR(kernel='rbf'))\n",
    "svr_rbf.fit(X_train, y_train)\n",
    "mse_svr_rbf = mean_squared_error(y_test, svr_rbf.predict(X_test))\n",
    "\n",
    "# Hyperparameter tuning for SVR with RBF kernel\n",
    "param_grid = {\n",
    "    'svr__C': [0.1, 1, 10, 100],\n",
    "    'svr__gamma': [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "grid = GridSearchCV(svr_rbf, param_grid, scoring='neg_mean_squared_error', refit=True, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "best_svr_rbf = grid.best_estimator_\n",
    "mse_best_svr_rbf = mean_squared_error(y_test, best_svr_rbf.predict(X_test))\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "mse_rf = mean_squared_error(y_test, rf_reg.predict(X_test))\n",
    "\n",
    "# Compare mean squared errors\n",
    "print(\"Mean Squared Error comparison:\")\n",
    "print(\"SVR with standardization (linear) --> %.3f\" % mse_svr_linear)\n",
    "print(\"SVR with standardization (RBF) --> %.3f\" % mse_svr_rbf)\n",
    "print(\"Tuned SVR with standardization (RBF) --> %.3f\" % mse_best_svr_rbf)\n",
    "print(\"Random Forest --> %.3f\" % mse_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb883b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy comparison:\n",
      "Gaussian Naive Bayes --> 20.815%\n",
      "SVM (linear) --> 41.928%\n",
      "SVM with standardization (linear) --> 45.968%\n",
      "SVM (RBF) --> 42.627%\n",
      "SVM with standardization (RBF) --> 47.577%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "retractions = pd.read_csv(\"retractions35215.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "retractions['Publication_Year'] = pd.to_datetime(retractions['OriginalPaperDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Year'] = pd.to_datetime(retractions['RetractionDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Lag'] = (retractions['Retraction_Year'] - retractions['Publication_Year']) / 365.25\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['CitationCount', 'Retraction_Lag', 'ArticleType']\n",
    "retractions['ArticleType'] = retractions['ArticleType'].astype('category').cat.codes\n",
    "\n",
    "# Use 'Reason' as the target variable and encode it\n",
    "retractions['Reason'] = retractions['Reason'].astype('category').cat.codes\n",
    "y = retractions['Reason']\n",
    "\n",
    "# Filter for top n most frequent classes\n",
    "n = 10\n",
    "top_classes = y.value_counts().index[:n]\n",
    "filtered_data = retractions[retractions['Reason'].isin(top_classes)]\n",
    "\n",
    "X = filtered_data[features]\n",
    "y = filtered_data['Reason']\n",
    "\n",
    "# Ensure balanced splitting using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=0)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# SVM with no standardization (linear kernel)\n",
    "svm_clf_linear = SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_pred_svm_linear = svm_clf_linear.predict(X_test)\n",
    "acc_svm_linear = accuracy_score(y_test, y_pred_svm_linear)\n",
    "\n",
    "# SVM with standardization via pipeline (linear kernel)\n",
    "pipe_linear = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "acc_svm_linear_std = pipe_linear.score(X_test, y_test)\n",
    "\n",
    "# SVM with RBF kernel and no standardization\n",
    "svm_clf_rbf = SVC(kernel='rbf').fit(X_train, y_train)\n",
    "y_pred_svm_rbf = svm_clf_rbf.predict(X_test)\n",
    "acc_svm_rbf = accuracy_score(y_test, y_pred_svm_rbf)\n",
    "\n",
    "# SVM with standardization via pipeline (RBF kernel)\n",
    "pipe_rbf = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "pipe_rbf.fit(X_train, y_train)\n",
    "acc_svm_rbf_std = pipe_rbf.score(X_test, y_test)\n",
    "\n",
    "# Compare accuracy scores\n",
    "print(\"Accuracy comparison:\")\n",
    "print(\"Gaussian Naive Bayes --> %.3f%%\" % (acc_gnb * 100))\n",
    "print(\"SVM (linear) --> %.3f%%\" % (acc_svm_linear * 100))\n",
    "print(\"SVM with standardization (linear) --> %.3f%%\" % (acc_svm_linear_std * 100))\n",
    "print(\"SVM (RBF) --> %.3f%%\" % (acc_svm_rbf * 100))\n",
    "print(\"SVM with standardization (RBF) --> %.3f%%\" % (acc_svm_rbf_std * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1363220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"retractions35215.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['ArticleType'] = label_encoder.fit_transform(df['ArticleType'])\n",
    "df['RetractionNature'] = label_encoder.fit_transform(df['RetractionNature'])\n",
    "\n",
    "# Define Features (X) and Target Variable (y)\n",
    "features = ['CitationCount', 'ArticleType']\n",
    "X = df[features]\n",
    "y = df['RetractionNature']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585abec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy comparison:\n",
      "Gaussian Naive Bayes --> 20.815%\n",
      "SVM (linear) --> 41.928%\n",
      "SVM with standardization (linear) --> 45.968%\n",
      "SVM (RBF) --> 42.627%\n",
      "SVM with standardization (RBF) --> 47.577%\n",
      "Random Forest --> 47.140%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "retractions = pd.read_csv(\"retractions35215.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "retractions['Publication_Year'] = pd.to_datetime(retractions['OriginalPaperDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Year'] = pd.to_datetime(retractions['RetractionDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Lag'] = (retractions['Retraction_Year'] - retractions['Publication_Year']) / 365.25\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['CitationCount', 'Retraction_Lag', 'ArticleType']\n",
    "retractions['ArticleType'] = retractions['ArticleType'].astype('category').cat.codes\n",
    "\n",
    "# Use 'Reason' as the target variable and encode it\n",
    "retractions['Reason'] = retractions['Reason'].astype('category').cat.codes\n",
    "y = retractions['Reason']\n",
    "\n",
    "# Filter for top n most frequent classes\n",
    "n = 10\n",
    "top_classes = y.value_counts().index[:n]\n",
    "filtered_data = retractions[retractions['Reason'].isin(top_classes)]\n",
    "\n",
    "X = filtered_data[features]\n",
    "y = filtered_data['Reason']\n",
    "\n",
    "# Ensure balanced splitting using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=0)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# SVM with no standardization (linear kernel)\n",
    "svm_clf_linear = SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_pred_svm_linear = svm_clf_linear.predict(X_test)\n",
    "acc_svm_linear = accuracy_score(y_test, y_pred_svm_linear)\n",
    "\n",
    "# SVM with standardization via pipeline (linear kernel)\n",
    "pipe_linear = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "acc_svm_linear_std = pipe_linear.score(X_test, y_test)\n",
    "\n",
    "# SVM with RBF kernel and no standardization\n",
    "svm_clf_rbf = SVC(kernel='rbf').fit(X_train, y_train)\n",
    "y_pred_svm_rbf = svm_clf_rbf.predict(X_test)\n",
    "acc_svm_rbf = accuracy_score(y_test, y_pred_svm_rbf)\n",
    "\n",
    "# SVM with standardization via pipeline (RBF kernel)\n",
    "pipe_rbf = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "pipe_rbf.fit(X_train, y_train)\n",
    "acc_svm_rbf_std = pipe_rbf.score(X_test, y_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Compare accuracy scores\n",
    "print(\"Accuracy comparison:\")\n",
    "print(\"Gaussian Naive Bayes --> %.3f%%\" % (acc_gnb * 100))\n",
    "print(\"SVM (linear) --> %.3f%%\" % (acc_svm_linear * 100))\n",
    "print(\"SVM with standardization (linear) --> %.3f%%\" % (acc_svm_linear_std * 100))\n",
    "print(\"SVM (RBF) --> %.3f%%\" % (acc_svm_rbf * 100))\n",
    "print(\"SVM with standardization (RBF) --> %.3f%%\" % (acc_svm_rbf_std * 100))\n",
    "print(\"Random Forest --> %.3f%%\" % (acc_rf * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39382104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy comparison:\n",
      "Gaussian Naive Bayes --> 49.325%\n",
      "SVM (linear) --> 45.159%\n",
      "SVM with standardization (linear) --> 50.428%\n",
      "SVM (RBF) --> 46.433%\n",
      "SVM with standardization (RBF) --> 53.338%\n",
      "Random Forest --> 53.205%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "retractions = pd.read_csv('retractions35215.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "retractions = retractions.drop(['Title', 'URLS', 'RetractionDOI', 'OriginalPaperDOI', 'Notes', 'Subject', 'Journal', 'Publisher'], axis=1)\n",
    "\n",
    "# Handling missing values (Dropping Null Rows)\n",
    "retractions = retractions.dropna()\n",
    "\n",
    "# Feature Engineering\n",
    "retractions['Publication_Year'] = pd.to_datetime(retractions['OriginalPaperDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Year'] = pd.to_datetime(retractions['RetractionDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Lag'] = (retractions['Retraction_Year'] - retractions['Publication_Year']) / 365.25\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['CitationCount', 'Retraction_Lag', 'ArticleType']\n",
    "retractions['ArticleType'] = retractions['ArticleType'].astype('category').cat.codes\n",
    "\n",
    "# Use 'Reason' as the target variable and encode it\n",
    "retractions['Reason'] = retractions['Reason'].astype('category').cat.codes\n",
    "y = retractions['Reason']\n",
    "\n",
    "# Filter for top n most frequent classes\n",
    "n = 10\n",
    "top_classes = y.value_counts().index[:n]\n",
    "filtered_data = retractions[retractions['Reason'].isin(top_classes)]\n",
    "\n",
    "X = filtered_data[features]\n",
    "y = filtered_data['Reason']\n",
    "\n",
    "# Ensure balanced splitting using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=0)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# SVM with no standardization (linear kernel)\n",
    "svm_clf_linear = SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_pred_svm_linear = svm_clf_linear.predict(X_test)\n",
    "acc_svm_linear = accuracy_score(y_test, y_pred_svm_linear)\n",
    "\n",
    "# SVM with standardization via pipeline (linear kernel)\n",
    "pipe_linear = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "pipe_linear.fit(X_train, y_train)\n",
    "acc_svm_linear_std = pipe_linear.score(X_test, y_test)\n",
    "\n",
    "# SVM with RBF kernel and no standardization\n",
    "svm_clf_rbf = SVC(kernel='rbf').fit(X_train, y_train)\n",
    "y_pred_svm_rbf = svm_clf_rbf.predict(X_test)\n",
    "acc_svm_rbf = accuracy_score(y_test, y_pred_svm_rbf)\n",
    "\n",
    "# SVM with standardization via pipeline (RBF kernel)\n",
    "pipe_rbf = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "pipe_rbf.fit(X_train, y_train)\n",
    "acc_svm_rbf_std = pipe_rbf.score(X_test, y_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Compare accuracy scores\n",
    "print(\"Accuracy comparison:\")\n",
    "print(\"Gaussian Naive Bayes --> %.3f%%\" % (acc_gnb * 100))\n",
    "print(\"SVM (linear) --> %.3f%%\" % (acc_svm_linear * 100))\n",
    "print(\"SVM with standardization (linear) --> %.3f%%\" % (acc_svm_linear_std * 100))\n",
    "print(\"SVM (RBF) --> %.3f%%\" % (acc_svm_rbf * 100))\n",
    "print(\"SVM with standardization (RBF) --> %.3f%%\" % (acc_svm_rbf_std * 100))\n",
    "print(\"Random Forest --> %.3f%%\" % (acc_rf * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b14cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Classification Metrics---\n",
      "Accuracy: 0.532\n",
      "Precision: 0.430\n",
      "Recall: 0.532\n",
      "F1-score: 0.446\n",
      "\n",
      "---Regression Metrics---\n",
      "Mean Squared Error (MSE): 4545874.215\n",
      "Mean Absolute Error (MAE): 1786.251\n",
      "Root Mean Squared Error (RMSE): 2132.106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "retractions = pd.read_csv('retractions35215.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "retractions = retractions.drop(['Title', 'URLS', 'RetractionDOI', 'OriginalPaperDOI', 'Notes', 'Subject', 'Journal', 'Publisher'], axis=1)\n",
    "\n",
    "# Handling missing values (Dropping Null Rows)\n",
    "retractions = retractions.dropna()\n",
    "\n",
    "# Feature Engineering\n",
    "retractions['Publication_Year'] = pd.to_datetime(retractions['OriginalPaperDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Year'] = pd.to_datetime(retractions['RetractionDate'], format='%d/%m/%Y', dayfirst=True).dt.year\n",
    "retractions['Retraction_Lag'] = (retractions['Retraction_Year'] - retractions['Publication_Year']) / 365.25\n",
    "\n",
    "# Select features and target variable\n",
    "features = ['CitationCount', 'Retraction_Lag', 'ArticleType']\n",
    "retractions['ArticleType'] = retractions['ArticleType'].astype('category').cat.codes\n",
    "\n",
    "# Use 'Reason' as the target variable and encode it\n",
    "retractions['Reason'] = retractions['Reason'].astype('category').cat.codes\n",
    "y = retractions['Reason']\n",
    "\n",
    "# Filter for top n most frequent classes\n",
    "n = 10\n",
    "top_classes = y.value_counts().index[:n]\n",
    "filtered_data = retractions[retractions['Reason'].isin(top_classes)]\n",
    "\n",
    "X = filtered_data[features]\n",
    "y = filtered_data['Reason']\n",
    "\n",
    "# Ensure balanced splitting using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=0)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Compute classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# Print classification metrics\n",
    "print(\"---Classification Metrics---\")\n",
    "print(\"Accuracy: %.3f\" % accuracy)\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"F1-score: %.3f\" % f1)\n",
    "\n",
    "# Random Forest Regressor \n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "y_pred_reg = rf_reg.predict(X_test)\n",
    "\n",
    "# Compute regression metrics\n",
    "mse = mean_squared_error(y_test, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print regression metrics\n",
    "print(\"\\n---Regression Metrics---\")\n",
    "print(\"Mean Squared Error (MSE): %.3f\" % mse)\n",
    "print(\"Mean Absolute Error (MAE): %.3f\" % mae)\n",
    "print(\"Root Mean Squared Error (RMSE): %.3f\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767091b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
